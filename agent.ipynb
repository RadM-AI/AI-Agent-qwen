{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2874eb",
   "metadata": {
    "id": "dc2874eb"
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.8.0+cu126 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbe4b83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6383,
     "status": "ok",
     "timestamp": 1759993876162,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "2cbe4b83",
    "outputId": "a07442a9-eff8-445b-987d-5981a9dd30e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.8-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langchain_huggingface\n",
      "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: filelock in c:\\program files\\python311-64\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers[torch])\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\program files\\python311-64\\lib\\site-packages (from transformers[torch]) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python311-64\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers[torch])\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Downloading regex-2025.9.18-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers[torch])\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers[torch])\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers[torch])\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers[torch])\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: torch>=2.2 in c:\\program files\\python311-64\\lib\\site-packages (from transformers[torch]) (2.8.0+cu126)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\program files\\python311-64\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.33-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.12.0-py3-none-any.whl.metadata (83 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.3-cp311-cp311-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.41.1-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers[torch])\n",
      "  Downloading charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers[torch])\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.13.0-cp311-cp311-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.2-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.8.0-cp311-cp311-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.7.0-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.4.1-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.22.0-cp311-cp311-win_amd64.whl.metadata (77 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain_community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\program files\\python311-64\\lib\\site-packages (from torch>=2.2->transformers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\program files\\python311-64\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python311-64\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python311-64\\lib\\site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python311-64\\lib\\site-packages (from jinja2->torch>=2.2->transformers[torch]) (2.1.5)\n",
      "Downloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.0 MB 149.8 kB/s eta 0:01:17\n",
      "   - -------------------------------------- 0.5/12.0 MB 149.8 kB/s eta 0:01:17\n",
      "   - -------------------------------------- 0.5/12.0 MB 149.8 kB/s eta 0:01:17\n",
      "   - -------------------------------------- 0.5/12.0 MB 149.8 kB/s eta 0:01:17\n",
      "   - -------------------------------------- 0.5/12.0 MB 149.8 kB/s eta 0:01:17\n",
      "   - -------------------------------------- 0.5/12.0 MB 149.8 kB/s eta 0:01:17\n",
      "   - -------------------------------------- 0.5/12.0 MB 149.8 kB/s eta 0:01:17\n",
      "   - -------------------------------------- 0.5/12.0 MB 149.8 kB/s eta 0:01:17\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.8/12.0 MB 153.9 kB/s eta 0:01:13\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   --- ------------------------------------ 1.0/12.0 MB 134.6 kB/s eta 0:01:22\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 124.7 kB/s eta 0:01:26\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 107.8 kB/s eta 0:01:37\n",
      "   ------ --------------------------------- 1.8/12.0 MB 111.9 kB/s eta 0:01:31\n",
      "   ------ --------------------------------- 1.8/12.0 MB 111.9 kB/s eta 0:01:31\n",
      "   ------ --------------------------------- 1.8/12.0 MB 111.9 kB/s eta 0:01:31\n",
      "   ------ --------------------------------- 1.8/12.0 MB 111.9 kB/s eta 0:01:31\n",
      "   ------ --------------------------------- 1.8/12.0 MB 111.9 kB/s eta 0:01:31\n",
      "   ------ --------------------------------- 2.1/12.0 MB 122.3 kB/s eta 0:01:21\n",
      "   ------ --------------------------------- 2.1/12.0 MB 122.3 kB/s eta 0:01:21\n",
      "   ------ --------------------------------- 2.1/12.0 MB 122.3 kB/s eta 0:01:21\n",
      "   ------- -------------------------------- 2.4/12.0 MB 133.4 kB/s eta 0:01:13\n",
      "   ------- -------------------------------- 2.4/12.0 MB 133.4 kB/s eta 0:01:13\n",
      "   -------- ------------------------------- 2.6/12.0 MB 145.6 kB/s eta 0:01:05\n",
      "   -------- ------------------------------- 2.6/12.0 MB 145.6 kB/s eta 0:01:05\n",
      "   -------- ------------------------------- 2.6/12.0 MB 145.6 kB/s eta 0:01:05\n",
      "   --------- ------------------------------ 2.9/12.0 MB 157.4 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 2.9/12.0 MB 157.4 kB/s eta 0:00:58\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 168.2 kB/s eta 0:00:53\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 168.2 kB/s eta 0:00:53\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 178.2 kB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 178.2 kB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 178.2 kB/s eta 0:00:49\n",
      "   ------------ --------------------------- 3.7/12.0 MB 188.0 kB/s eta 0:00:45\n",
      "   ------------- -------------------------- 3.9/12.0 MB 198.6 kB/s eta 0:00:41\n",
      "   ------------- -------------------------- 3.9/12.0 MB 198.6 kB/s eta 0:00:41\n",
      "   ------------- -------------------------- 4.2/12.0 MB 209.0 kB/s eta 0:00:38\n",
      "   -------------- ------------------------- 4.5/12.0 MB 219.1 kB/s eta 0:00:35\n",
      "   -------------- ------------------------- 4.5/12.0 MB 219.1 kB/s eta 0:00:35\n",
      "   --------------- ------------------------ 4.7/12.0 MB 229.5 kB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 5.0/12.0 MB 239.7 kB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 5.2/12.0 MB 250.4 kB/s eta 0:00:27\n",
      "   ------------------ --------------------- 5.5/12.0 MB 261.7 kB/s eta 0:00:25\n",
      "   ------------------- -------------------- 5.8/12.0 MB 272.1 kB/s eta 0:00:23\n",
      "   -------------------- ------------------- 6.0/12.0 MB 281.8 kB/s eta 0:00:22\n",
      "   -------------------- ------------------- 6.3/12.0 MB 292.1 kB/s eta 0:00:20\n",
      "   --------------------- ------------------ 6.6/12.0 MB 302.3 kB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 311.8 kB/s eta 0:00:17\n",
      "   ------------------------ --------------- 7.3/12.0 MB 331.6 kB/s eta 0:00:15\n",
      "   ------------------------- -------------- 7.6/12.0 MB 341.9 kB/s eta 0:00:13\n",
      "   -------------------------- ------------- 7.9/12.0 MB 351.0 kB/s eta 0:00:12\n",
      "   --------------------------- ------------ 8.1/12.0 MB 360.3 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 8.4/12.0 MB 366.3 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 386.6 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 9.2/12.0 MB 395.3 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 9.4/12.0 MB 403.8 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 9.7/12.0 MB 411.7 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 9.7/12.0 MB 411.7 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.2/12.0 MB 427.3 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 10.5/12.0 MB 434.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 10.7/12.0 MB 442.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 11.0/12.0 MB 449.3 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 11.3/12.0 MB 456.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  11.8/12.0 MB 472.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 477.2 kB/s  0:00:26\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 0.0/564.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/564.3 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 262.1/564.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 564.3/564.3 kB 1.2 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.0/2.7 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.8/2.7 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 1.6 MB/s  0:00:01\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 3.7 MB/s  0:00:00\n",
      "Downloading langchain_core-0.3.78-py3-none-any.whl (449 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.4.33-py3-none-any.whl (387 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading pydantic-2.12.0-py3-none-any.whl (459 kB)\n",
      "Downloading pydantic_core-2.41.1-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.8/2.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 1.9 MB/s  0:00:01\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 2.0 MB/s  0:00:01\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.6/2.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.5 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 1.8 MB/s  0:00:01\n",
      "Downloading aiohttp-3.13.0-cp311-cp311-win_amd64.whl (454 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp311-cp311-win_amd64.whl (46 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.22.0-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Downloading langgraph-0.6.8-py3-none-any.whl (154 kB)\n",
      "Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading frozenlist-1.8.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl (299 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading orjson-3.11.3-cp311-cp311-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl (112 kB)\n",
      "Downloading propcache-0.4.1-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2025.9.18-cp311-cp311-win_amd64.whl (276 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, typing-inspection, tqdm, tenacity, sniffio, safetensors, regex, pyyaml, python-dotenv, pydantic-core, propcache, ormsgpack, orjson, mypy-extensions, multidict, marshmallow, jsonpointer, idna, httpx-sse, h11, greenlet, frozenlist, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, pydantic-settings, huggingface-hub, httpx, dataclasses-json, aiohttp, tokenizers, langsmith, langgraph-sdk, accelerate, transformers, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_huggingface, langgraph-prebuilt, langchain, langgraph, langchain_community\n",
      "\n",
      "   -- -------------------------------------  4/57 [tqdm]\n",
      "   ------ ---------------------------------  9/57 [pyyaml]\n",
      "   ------------- -------------------------- 19/57 [idna]\n",
      "   ---------------- ----------------------- 24/57 [charset_normalizer]\n",
      "   --------------------- ------------------ 31/57 [SQLAlchemy]\n",
      "   --------------------- ------------------ 31/57 [SQLAlchemy]\n",
      "   --------------------- ------------------ 31/57 [SQLAlchemy]\n",
      "   --------------------- ------------------ 31/57 [SQLAlchemy]\n",
      "   --------------------- ------------------ 31/57 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 32/57 [requests]\n",
      "   ----------------------- ---------------- 33/57 [pydantic]\n",
      "   ------------------------ --------------- 35/57 [httpcore]\n",
      "   --------------------------- ------------ 39/57 [pydantic-settings]\n",
      "   ---------------------------- ----------- 40/57 [huggingface-hub]\n",
      "   ---------------------------- ----------- 41/57 [httpx]\n",
      "   ------------------------------ --------- 43/57 [aiohttp]\n",
      "   ------------------------------- -------- 45/57 [langsmith]\n",
      "   -------------------------------- ------- 47/57 [accelerate]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   --------------------------------- ------ 48/57 [transformers]\n",
      "   ---------------------------------- ----- 49/57 [langchain-core]\n",
      "   ----------------------------------- ---- 50/57 [langgraph-checkpoint]\n",
      "   ------------------------------------- -- 54/57 [langchain]\n",
      "   ------------------------------------- -- 54/57 [langchain]\n",
      "   ------------------------------------- -- 54/57 [langchain]\n",
      "   ------------------------------------- -- 54/57 [langchain]\n",
      "   ------------------------------------- -- 54/57 [langchain]\n",
      "   ------------------------------------- -- 54/57 [langchain]\n",
      "   ------------------------------------- -- 54/57 [langchain]\n",
      "   -------------------------------------- - 55/57 [langgraph]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------  56/57 [langchain_community]\n",
      "   ---------------------------------------- 57/57 [langchain_community]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.43 accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.13.0 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 certifi-2025.10.5 charset_normalizer-3.4.3 dataclasses-json-0.6.7 frozenlist-1.8.0 greenlet-3.2.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.2 huggingface-hub-0.35.3 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-core-0.3.78 langchain-text-splitters-0.3.11 langchain_community-0.3.31 langchain_huggingface-0.3.1 langgraph-0.6.8 langgraph-checkpoint-2.1.2 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 langsmith-0.4.33 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 orjson-3.11.3 ormsgpack-1.11.0 propcache-0.4.1 pydantic-2.12.0 pydantic-core-2.41.1 pydantic-settings-2.11.0 python-dotenv-1.1.1 pyyaml-6.0.3 regex-2025.9.18 requests-2.32.5 requests-toolbelt-1.0.0 safetensors-0.6.2 sniffio-1.3.1 tenacity-9.1.2 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.0 typing-inspect-0.9.0 typing-inspection-0.4.2 urllib3-2.5.0 xxhash-3.6.0 yarl-1.22.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch] langchain langchain_community langgraph langchain_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5aecb",
   "metadata": {
    "id": "35a5aecb"
   },
   "source": [
    "# Основной рабочий пайплайн работы с агентом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f15af15",
   "metadata": {
    "executionInfo": {
     "elapsed": 9416,
     "status": "ok",
     "timestamp": 1759994950258,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "7f15af15"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111816f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "9a9175d57e204c1c89e1e5c24b0d29f0",
      "9afd692b222c4639ba287f31c923452f",
      "62398de8934a44fe8629c6e0f8a13ad9",
      "db55a5e3f2a747498100e4aa133c8fe4",
      "ac52d80557254e4387bbf491b6e5de68",
      "797b1e7713084d96ae46de8761ba7ba1",
      "06dceec0641d472d8453a962ba1636d5",
      "fff204dd37ee4cb2ac97ced50d3d6f69",
      "d85a61adc13f424fb565b911f47da686",
      "e271548820bb432da985076b101c8858",
      "63001596e0684eeba5f059342c344201"
     ]
    },
    "id": "111816f6",
    "outputId": "e3076b5d-4a5e-47f5-e62b-5e0aaf23fe60"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9175d57e204c1c89e1e5c24b0d29f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Qwen/Qwen2.5-0.5B-Instruct\n",
    "model_id = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe64c78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "84fb1527ad254f8586734e7617501cb9",
      "bbcc9d10adf34f0a936c71113422513b",
      "2141cb86b62c40be9eff3162b929be12",
      "c3da1f3194bd404e999b3bc866e8631d",
      "77502c3ca74a425d8fcb732c1e1abc6c",
      "8db1b5f644464c4284d0c749c12b5957",
      "af5f814390cd4a3da8f20e93daaceb3f",
      "f8418a6daef94d75a324bf5474bb121e",
      "a7df595a616e4fde9746a989fe76bcb9",
      "155ec4569167476f99bb31eb4019d75a",
      "4d6cd15424274151979152315e324508",
      "a9bc423644f24413942ddac7f722f95a",
      "0de1e0a1a893440b9129cfaac6b6855e",
      "0b57d6c594bf46a5962a3e779f893e57",
      "53e09b09d9064297a0f44089b915d9bb",
      "334b94ae140f4bc9bf502f0e42b8830a",
      "ebb015ac451f47e4b48cc691f2c67e9a",
      "8d0772ef4dcb4cfb9d543200f6ae9324",
      "068e34fef5fc4af6a4f5202e16deb678",
      "fd9e244c097b4fef8876683079f0be45",
      "d8b55a6d406b49dd80056981b5906e6b",
      "93ab1053135b4c2faa3ef5b6002d77e1"
     ]
    },
    "executionInfo": {
     "elapsed": 36382,
     "status": "ok",
     "timestamp": 1759994986644,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "afe64c78",
    "outputId": "4af19d8a-6f33-4598-b905-6d383e4fce4c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81822f982ae54f23865ceccc8621ae8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    'Qwen/Qwen2.5-3B-Instruct',\n",
    "    temperature = 0.001,\n",
    "    max_new_tokens=1000,\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1633282b",
   "metadata": {
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1759994994154,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "1633282b"
   },
   "outputs": [],
   "source": [
    "hf_pipeline = HuggingFacePipeline(pipeline=pipe)\n",
    "chat_model = ChatHuggingFace(llm=hf_pipeline,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d89d0f",
   "metadata": {
    "id": "57d89d0f"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0d25e",
   "metadata": {
    "id": "b6d0d25e"
   },
   "outputs": [],
   "source": [
    "class Subtopic(BaseModel):\n",
    "  title: str = Field(..., description = 'Technocal title of subtopic')\n",
    "  description: str = Field(..., description = '1-2 sentence explantion')\n",
    "\n",
    "class SubtopicList(BaseModel):\n",
    "  subtopics: List[Subtopic]\n",
    "\n",
    "\n",
    "parser =PydanticOutputParser(pydantic_object=SubtopicList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b65a03",
   "metadata": {
    "id": "e3b65a03"
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=(\n",
    "    '''\n",
    "{format_insrt}\\n\n",
    "You're a machine learning expert.\\n\n",
    "There's a topic: {topic}\\n\n",
    "Compose the titles of 3 articles that fit this topic.\\n\n",
    "Please answer in Russian.\\n\n",
    "Output JSON object: {{{{\"subtopics\": [{{{{\"title\": \"...\", \"description\": \"...\"}}}}, ...]}}}}\\n\n",
    "    '''),\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_insrt': parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ee08e3",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759995012031,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "e7ee08e3"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import Runnable\n",
    "from typing import Optional, Any\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "class TrimResponseRunnable(Runnable):\n",
    "    def invoke(self, input: Any, config: Optional[RunnableConfig] = None, **kwargs: Any) -> Any:\n",
    "        text = input\n",
    "        if hasattr(text, \"content\"):\n",
    "            text.content = text.content\n",
    "        start_pos = text.content.find('<|im_start|>assistant')\n",
    "        if start_pos != -1:\n",
    "            text.content = text.content[start_pos+len('<|im_start|>assistant'):]\n",
    "        return text\n",
    "trim_response = TrimResponseRunnable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834595f1",
   "metadata": {
    "id": "834595f1"
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | chat_model | trim_response | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad34692",
   "metadata": {
    "id": "0ad34692"
   },
   "outputs": [],
   "source": [
    "responce = chain.invoke({'topic':'Машинное обучение в России'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e497de",
   "metadata": {
    "id": "28e497de",
    "outputId": "1da69cd2-e780-4846-973b-6f355d1cef1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>assistant\n",
      "```json\n",
      "{\n",
      "    \"subtopics\": [\n",
      "        {\n",
      "            \"title\": \"Машинное обучение в России: Начальные принципы\",\n",
      "            \"description\": \"Этот раздел рассказывает о основных принципах и методах обучения машинного intelligence в России. Содержит информацию о различных подходах к обучению машинного обучения, алгоритмах, системам обучения и их применении.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Машинное обучение в России: Современные технологии\",\n",
      "            \"description\": \"Этот раздел описывает современные технологии в области машинного обучения, такие как искусственный интеллект, нейронные сети и др. В этом разделе будет рассмотрено использование таких технологий в различных сферах жизни и бизнеса.\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Машинное обучение в России: Проблемы и возможности\",\n",
      "            \"description\": \"Этот раздел обсуждает проблемы и возможности применения машинного обучения в России. Он включает в себя анализ проблем, связанных с обучением машинного обучения, а также обсуждается возможные решения и возможности для развития этой области.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(responce.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0be16",
   "metadata": {
    "id": "08f0be16"
   },
   "source": [
    "## Использование инструментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ecfd22",
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1759994999946,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "b9ecfd22"
   },
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import requests\n",
    "import json\n",
    "\n",
    "@tool\n",
    "def get_weather(input: str) -> str:\n",
    "    \"\"\"Get the current weather for the specified city.\n",
    "\n",
    "    Args:\n",
    "        input: The name of the city in Russian (for example: 'Москва', 'Санкт-Петербург')\n",
    "\n",
    "    Returns:\n",
    "        A line with information about temperature and weather conditions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Демо-версия без реального API\n",
    "        weather_data = {\n",
    "            \"Москва\": \"🌤️ +15°C, облачно с прояснениями\",\n",
    "            \"Санкт-Петербург\": \"🌧️ +12°C, небольшой дождь\",\n",
    "            \"Сочи\": \"☀️ +22°C, солнечно\",\n",
    "            \"Новосибирск\": \"❄️ -5°C, снег\"\n",
    "        }\n",
    "        return weather_data.get(input, f\"Погода для {input} временно недоступна\")\n",
    "    except Exception as e:\n",
    "        return f\"Ошибка: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def calculate(input: str) -> str:\n",
    "    \"\"\"Calculate a mathematical expression.\n",
    "\n",
    "    Args:\n",
    "        input: A mathematical expression (for example: '2 + 2 * 3', ' sin(45)')\n",
    "\n",
    "    Returns:\n",
    "        Calculation result\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Безопасное вычисление\n",
    "        allowed_chars = set('0123456789+-*/.() ')\n",
    "        if all(c in allowed_chars for c in input):\n",
    "            result = eval(input)\n",
    "            return f\"Результат: {input} = {result}\"\n",
    "        else:\n",
    "            return \"Ошибка: выражение содержит недопустимые символы\"\n",
    "    except Exception as e:\n",
    "        return f\"Ошибка вычисления: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def search_information(input: str) -> str:\n",
    "    \"\"\"Search for information on a given query.\n",
    "\n",
    "    Args:\n",
    "        input: A search query in Russian\n",
    "\n",
    "    Returns:\n",
    "        Information found\n",
    "    \"\"\"\n",
    "    # Демо-версия поиска\n",
    "    knowledge_base = {\n",
    "        \"столица россии\": \"Столица России - Москва\",\n",
    "        \"самая длинная река\": \"Самая длинная река в России - Лена (4400 км)\",\n",
    "        \"население москвы\": \"Население Москвы около 13 миллионов человек\"\n",
    "    }\n",
    "\n",
    "    query_lower = input.lower()\n",
    "    for key, value in knowledge_base.items():\n",
    "        if key in query_lower:\n",
    "            return value\n",
    "\n",
    "    return f\"По запросу '{input}' информация не найдена в базе знаний\"\n",
    "\n",
    "# Создаем список инструментов\n",
    "tools = [get_weather, calculate, search_information]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581a954",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759997175673,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "7581a954"
   },
   "outputs": [],
   "source": [
    "def format_tools_description(tools_list):\n",
    "    descriptions = []\n",
    "    for tool in tools_list:\n",
    "        desc = f\"\"\"{tool.name}:\n",
    "   - Description: {tool.description}\n",
    "   - Input data: {', '.join([f'{param_name}: {param_type}' for param_name, param_type in tool.args.items()])}\"\"\"\n",
    "        descriptions.append(desc)\n",
    "    return \"\\n\\n\".join(descriptions)\n",
    "\n",
    "tools_description = format_tools_description(tools)\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=(\n",
    "'''\n",
    "You are an intelligent assistant with access to the following tools:\n",
    "\n",
    "AVAILABLE TOOLS:\n",
    "{tools_description}\n",
    "\n",
    "\n",
    "INSTRUCTIONS FOR USE:\n",
    "  1. Carefully analyze the user's request\n",
    "  2. Determine if you need a response tool.\n",
    "  3. Use ONLY the tools from the list of AVAILABLE TOOLS.\n",
    "  4. If you NEED a tool to respond, start the response with the [TOOL] tag and then place the JSON object.\n",
    "  5. If you DON'T NEED the tool, reply in plain text.\n",
    "\n",
    "examples:\n",
    "\n",
    "Query: \"Какая погода в Москве?\"\n",
    "Response: [TOOL] {{\"tool\": \"get_weather\", \"input\": \"Москва\"}}\n",
    "\n",
    "Request: \"Привет! Как дела?\"\n",
    "Answer: Привет! Я ИИ ассистент. Чем могу помочь?\n",
    "\n",
    "STRICT RULES:\n",
    "- DON'T FORGET that YOU can communicate with the user and keep the conversation going.\n",
    "- NEVER write explanations before or after JSON\n",
    "- NEVER use keys other than \"tool\", \"input\"\n",
    "- NEVER come up with new tool names - use ONLY AVAILABLE TOOLS from the list.\n",
    "- There must be a [TOOL] BEFORE the JSON.\n",
    "- ANSWER AND VALUE IN RUSSIAN\n",
    "\n",
    "\n",
    "\n",
    "USER'S QUESTION: {input}\n",
    "\n",
    "'''),\n",
    "    input_variables=['input'],\n",
    "    partial_variables={'tools_description': tools_description},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cunqljrKA-B-",
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1759998511171,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "cunqljrKA-B-"
   },
   "outputs": [],
   "source": [
    "ask_result_quest = PromptTemplate(\n",
    "    input_variables=[\"user_question\", \"previous_result\"],\n",
    "    template=(\n",
    "        \"Был вопрос пользователя:\\n{user_question}\\n\"\n",
    "        \"Из инструмента ты выяснил, что:\\n{previous_result}\\n\"\n",
    "        \"Проанализируй результат работы инструмента и дай ответ пользователю ПОНЯТНО БЕЗ ЛИШНЕГО.\"\n",
    "        \"НИЧЕГО НЕ придумывай и НЕ дополняй. Работай с тем что есть.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "JACOaLQ96Rj7",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1759998724581,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "JACOaLQ96Rj7"
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | chat_model | trim_response | process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "C139Wp276142",
   "metadata": {
    "executionInfo": {
     "elapsed": 2346,
     "status": "ok",
     "timestamp": 1759998436329,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "C139Wp276142"
   },
   "outputs": [],
   "source": [
    "resp = {'input':'Когда родился Александр Пушкин?'}\n",
    "responce = chain.invoke(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lg6IcOA3EHgW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759998437375,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "lg6IcOA3EHgW",
    "outputId": "8f0b8673-19e1-4c30-e5e3-04a3aa4d928a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nИзвините, но информация о том, когда родился Александр Пушкин, не найдена в базе знаний.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "kxMo_DacD9q3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759998445215,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "kxMo_DacD9q3",
    "outputId": "1906e305-a77f-4410-a404-5dcf4b8690a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"По запросу 'Когда родился Александр Пушкин' информация не найдена в базе знаний\", additional_kwargs={}, response_metadata={}, id='run--bd33b3b9-25c9-4fb3-874a-d030485a6177-0')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.invoke(responce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "TFtLDdYaCnh_",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759998808674,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "TFtLDdYaCnh_"
   },
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "def get_result(responce):\n",
    "  # Создаем цепочку для нового шага\n",
    "  ask_chain = ask_result_quest | chat_model | trim_response\n",
    "\n",
    "  # Вызов с переданными переменными\n",
    "  result = ask_chain.invoke({\n",
    "      \"user_question\": resp['input'],\n",
    "      \"previous_result\": responce\n",
    "  })\n",
    "  return result.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2xPIdBnO64gV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759998521947,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "2xPIdBnO64gV",
    "outputId": "b3bc354e-29b6-4990-b7f1-f3d7b5e59dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Информация о дате рождения Александра Пушкина не найдена в базе знаний.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vS46j9i39zDN",
   "metadata": {
    "id": "vS46j9i39zDN"
   },
   "outputs": [],
   "source": [
    "responce.content = responce.content.replace(\"query\", \"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43do_SHp7B0n",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1759995017276,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "43do_SHp7B0n"
   },
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "class ToolCall(BaseModel):\n",
    "    tool: Literal[\"get_weather\", \"search_information\", \"calculate\"]  # только разрешенные инструменты\n",
    "    input: str\n",
    "    # добавьте другие необходимые параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "buoVPZ-G7SMy",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759995017956,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "buoVPZ-G7SMy"
   },
   "outputs": [],
   "source": [
    "def is_valid_input(tool_name: str, input_data: str) -> bool:\n",
    "    \"\"\"Проверяет корректность входных данных для конкретного инструмента\"\"\"\n",
    "\n",
    "    validators = {\n",
    "        \"get_weather\": lambda x: len(x.strip()) > 0 and x.isprintable(),\n",
    "        \"search_information\": lambda x: len(x.strip()) >= 2,\n",
    "        \"calculate\": lambda x: is_valid_expression(x)\n",
    "    }\n",
    "\n",
    "    validator = validators.get(tool_name)\n",
    "    return validator(input_data) if validator else False\n",
    "\n",
    "def is_valid_expression(expr: str) -> bool:\n",
    "    \"\"\"Проверяет безопасность математического выражения\"\"\"\n",
    "    # Запрещаем опасные конструкции\n",
    "    dangerous_keywords = ['import', 'exec', 'eval', '__', 'open', 'file']\n",
    "    return all(keyword not in expr for keyword in dangerous_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o3p3ze9k7XZe",
   "metadata": {
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1759995018213,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "o3p3ze9k7XZe"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "def parse_ai_response(response_text: str) -> Optional[ToolCall]:\n",
    "    \"\"\"\n",
    "    Безопасно парсит ответ ИИ и валидирует его\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Пытаемся распарсить JSON\n",
    "        cleaned_response = response_text.strip()\n",
    "\n",
    "        # Убираем возможные markdown блоки кода\n",
    "        if cleaned_response.startswith('```json'):\n",
    "            cleaned_response = cleaned_response[7:]  # убираем ```json\n",
    "        if cleaned_response.endswith('```'):\n",
    "            cleaned_response = cleaned_response[:-3]  # убираем ```\n",
    "        cleaned_response = cleaned_response.strip()\n",
    "\n",
    "        data = json.loads(cleaned_response)\n",
    "\n",
    "        # Валидируем через Pydantic\n",
    "        tool_call = ToolCall(**data)\n",
    "\n",
    "        # Дополнительные проверки бизнес-логики\n",
    "        if not is_valid_input(tool_call.tool, tool_call.input):\n",
    "            logging.warning(f\"Invalid input for tool {tool_call.tool}: {tool_call.input}\")\n",
    "            return None\n",
    "\n",
    "        return tool_call\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Invalid JSON from AI: {e}\")\n",
    "        return None\n",
    "    except ValidationError as e:\n",
    "        logging.error(f\"Validation error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "VLq7M_SuXimr",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759998818527,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "VLq7M_SuXimr"
   },
   "outputs": [],
   "source": [
    "class ProcessAIResponse(Runnable):\n",
    "    def invoke(self, input: Any, config: Optional[RunnableConfig] = None, **kwargs: Any) -> Any:\n",
    "        text = input\n",
    "        if hasattr(text, \"content\"):\n",
    "            text.content = text.content\n",
    "        text.content = process_ai_response(text.content)\n",
    "        return text\n",
    "process = ProcessAIResponse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "SeX8WUZN7zl6",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759998817472,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "SeX8WUZN7zl6"
   },
   "outputs": [],
   "source": [
    "def process_ai_response(ai_response: str):\n",
    "    \"\"\"\n",
    "    Основной процесс обработки ответа ИИ\n",
    "    \"\"\"\n",
    "    # Парсим и валидируем\n",
    "    if '[TOOL]' in ai_response:\n",
    "      start = ai_response.find('[TOOL]')\n",
    "      ask = ai_response[start+7:].strip()\n",
    "      tool_call = parse_ai_response(ask)\n",
    "\n",
    "      if not tool_call:\n",
    "          # Обработка ошибки\n",
    "          return {\"error\": \"Invalid AI response\"}\n",
    "\n",
    "      # Выполняем соответствующий инструмент\n",
    "      try:\n",
    "          result = execute_tool(tool_call.tool, tool_call.input)\n",
    "          result = get_result(result)\n",
    "          return result\n",
    "      except Exception as e:\n",
    "          logging.error(f\"Tool execution failed: {e}\")\n",
    "          return {\"error\": f\"Tool execution failed: {str(e)}\"}\n",
    "\n",
    "    else:\n",
    "      return ai_response\n",
    "\n",
    "def execute_tool(tool_name: str, input_data: str):\n",
    "    \"\"\"Выполняет конкретный инструмент\"\"\"\n",
    "\n",
    "    tools = {\n",
    "        \"get_weather\": get_weather,\n",
    "        \"search_information\": search_information,\n",
    "        \"calculate\": calculate\n",
    "    }\n",
    "\n",
    "    if tool_name not in tools:\n",
    "        raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "\n",
    "    return tools[tool_name].invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ynLSa_3b8Qkh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1759950704293,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "ynLSa_3b8Qkh",
    "outputId": "263d981c-ecb0-4664-b416-a329436846c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True, 'result': 'Результат: 6 + 12 * 43 - 222 = 300'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_ai_response(responce.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V4Nvw09J8amz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1759948022051,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "V4Nvw09J8amz",
    "outputId": "c04a0436-62a6-4e2f-867a-d9f1ece66a92"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'{\"tool\": \"get_weather\", \"input\": \"Санкт-Петербург\"}'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responce.content[len('[TOOL]')+1:].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9_cq6vVPv9N",
   "metadata": {
    "id": "e9_cq6vVPv9N"
   },
   "source": [
    "## Память"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "l_l08DFHEco9",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759998859893,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "l_l08DFHEco9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2736\\3041127763.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Создаем память\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\",\n",
    "    input_key=\"input\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7SO27f-4Pyzk",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759998943957,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "7SO27f-4Pyzk"
   },
   "outputs": [],
   "source": [
    "def chat_with_memory():\n",
    "    while True:\n",
    "        user_input = input(\"Вы: \")\n",
    "        if user_input.lower() == 'выход':\n",
    "            break\n",
    "        resp['input'] = user_input\n",
    "        # Получаем историю из памяти\n",
    "        history = memory.load_memory_variables({})[\"history\"]\n",
    "        history_text = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in history])\n",
    "\n",
    "        # Генерируем ответ\n",
    "        response = chain.invoke({\n",
    "            \"input\": user_input,\n",
    "            \"history\": history_text\n",
    "        })\n",
    "\n",
    "        print(f\"Ассистент: {response.content}\")\n",
    "\n",
    "        # Сохраняем в память\n",
    "        memory.save_context({\"input\": user_input}, {\"output\": response.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KSJZNgJSQYm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139490,
     "status": "ok",
     "timestamp": 1759999084644,
     "user": {
      "displayName": "Rad AI",
      "userId": "08454794624271038601"
     },
     "user_tz": -180
    },
    "id": "KSJZNgJSQYm7",
    "outputId": "b2b6a05b-fa8c-42a3-f042-ec4743014ac0"
   },
   "outputs": [],
   "source": [
    "chat_with_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vEqzqqaZX2RF",
   "metadata": {
    "id": "vEqzqqaZX2RF"
   },
   "source": [
    "## Задачи\n",
    "\n",
    "* [ ] Построить граф состояний и определить случай, когда должна быть обратная связь\n",
    "* [ ] Разобраться с памятью и попробовать ее применить\n",
    "* [ ] Переходить от примера к конкретным инструментам по диплому"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l_-gJDLEYusW",
   "metadata": {
    "id": "l_-gJDLEYusW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "068e34fef5fc4af6a4f5202e16deb678": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06dceec0641d472d8453a962ba1636d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b57d6c594bf46a5962a3e779f893e57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_068e34fef5fc4af6a4f5202e16deb678",
      "max": 242,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd9e244c097b4fef8876683079f0be45",
      "value": 242
     }
    },
    "0de1e0a1a893440b9129cfaac6b6855e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebb015ac451f47e4b48cc691f2c67e9a",
      "placeholder": "​",
      "style": "IPY_MODEL_8d0772ef4dcb4cfb9d543200f6ae9324",
      "value": "generation_config.json: 100%"
     }
    },
    "155ec4569167476f99bb31eb4019d75a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2141cb86b62c40be9eff3162b929be12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8418a6daef94d75a324bf5474bb121e",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a7df595a616e4fde9746a989fe76bcb9",
      "value": 2
     }
    },
    "334b94ae140f4bc9bf502f0e42b8830a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d6cd15424274151979152315e324508": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53e09b09d9064297a0f44089b915d9bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8b55a6d406b49dd80056981b5906e6b",
      "placeholder": "​",
      "style": "IPY_MODEL_93ab1053135b4c2faa3ef5b6002d77e1",
      "value": " 242/242 [00:00&lt;00:00, 26.4kB/s]"
     }
    },
    "62398de8934a44fe8629c6e0f8a13ad9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fff204dd37ee4cb2ac97ced50d3d6f69",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d85a61adc13f424fb565b911f47da686",
      "value": 1
     }
    },
    "63001596e0684eeba5f059342c344201": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77502c3ca74a425d8fcb732c1e1abc6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "797b1e7713084d96ae46de8761ba7ba1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84fb1527ad254f8586734e7617501cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbcc9d10adf34f0a936c71113422513b",
       "IPY_MODEL_2141cb86b62c40be9eff3162b929be12",
       "IPY_MODEL_c3da1f3194bd404e999b3bc866e8631d"
      ],
      "layout": "IPY_MODEL_77502c3ca74a425d8fcb732c1e1abc6c"
     }
    },
    "8d0772ef4dcb4cfb9d543200f6ae9324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8db1b5f644464c4284d0c749c12b5957": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93ab1053135b4c2faa3ef5b6002d77e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a9175d57e204c1c89e1e5c24b0d29f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9afd692b222c4639ba287f31c923452f",
       "IPY_MODEL_62398de8934a44fe8629c6e0f8a13ad9",
       "IPY_MODEL_db55a5e3f2a747498100e4aa133c8fe4"
      ],
      "layout": "IPY_MODEL_ac52d80557254e4387bbf491b6e5de68"
     }
    },
    "9afd692b222c4639ba287f31c923452f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_797b1e7713084d96ae46de8761ba7ba1",
      "placeholder": "​",
      "style": "IPY_MODEL_06dceec0641d472d8453a962ba1636d5",
      "value": "Loading checkpoint shards:  50%"
     }
    },
    "a7df595a616e4fde9746a989fe76bcb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a9bc423644f24413942ddac7f722f95a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0de1e0a1a893440b9129cfaac6b6855e",
       "IPY_MODEL_0b57d6c594bf46a5962a3e779f893e57",
       "IPY_MODEL_53e09b09d9064297a0f44089b915d9bb"
      ],
      "layout": "IPY_MODEL_334b94ae140f4bc9bf502f0e42b8830a"
     }
    },
    "ac52d80557254e4387bbf491b6e5de68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af5f814390cd4a3da8f20e93daaceb3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbcc9d10adf34f0a936c71113422513b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8db1b5f644464c4284d0c749c12b5957",
      "placeholder": "​",
      "style": "IPY_MODEL_af5f814390cd4a3da8f20e93daaceb3f",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "c3da1f3194bd404e999b3bc866e8631d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_155ec4569167476f99bb31eb4019d75a",
      "placeholder": "​",
      "style": "IPY_MODEL_4d6cd15424274151979152315e324508",
      "value": " 2/2 [00:00&lt;00:00,  2.34it/s]"
     }
    },
    "d85a61adc13f424fb565b911f47da686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d8b55a6d406b49dd80056981b5906e6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db55a5e3f2a747498100e4aa133c8fe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e271548820bb432da985076b101c8858",
      "placeholder": "​",
      "style": "IPY_MODEL_63001596e0684eeba5f059342c344201",
      "value": " 1/2 [00:16&lt;00:16, 16.47s/it]"
     }
    },
    "e271548820bb432da985076b101c8858": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebb015ac451f47e4b48cc691f2c67e9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8418a6daef94d75a324bf5474bb121e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd9e244c097b4fef8876683079f0be45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fff204dd37ee4cb2ac97ced50d3d6f69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
